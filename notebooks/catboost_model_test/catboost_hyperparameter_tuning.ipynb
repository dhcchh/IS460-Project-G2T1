{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CatBoost Hyperparameter Tuning for Fraud Detection\n",
        "\n",
        "This notebook performs grid search style tuning for CatBoost with the same data, feature preset, and business cost evaluation as the VAE tuner.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment ready for CatBoost tuning.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('../..'))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "from itertools import product\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from src.evaluation import FraudEvaluationMetrics\n",
        "from src.vae_models.vae_base import FraudDataHandler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Environment ready for CatBoost tuning.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define Base Configuration and Parameter Grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter Tuning Configuration\n",
            "============================================================\n",
            "Total Configurations: 18\n",
            "  iterations     : [200, 400]\n",
            "  depth          : [4, 6, 8]\n",
            "  learning_rate  : [0.1, 0.05, 0.02]\n"
          ]
        }
      ],
      "source": [
        "base_config = {\n",
        "    'data_path': '../../data/processed/creditcard_fe.csv',\n",
        "    'drop_features': 'logreg_baseline',\n",
        "    'random_seed': 42,\n",
        "    'C_FP': 550,\n",
        "    'C_FN': 110,\n",
        "}\n",
        "\n",
        "param_grid = {\n",
        "    'iterations': [200, 400],\n",
        "    'depth': [4, 6, 8],\n",
        "    'learning_rate': [0.1, 0.05, 0.02]\n",
        "}\n",
        "\n",
        "total_configs = np.prod([len(v) for v in param_grid.values()])\n",
        "print(\"Hyperparameter Tuning Configuration\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total Configurations: {total_configs}\")\n",
        "for k, v in param_grid.items():\n",
        "    print(f\"  {k:15s}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Data Once\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from ../../data/processed/creditcard_fe.csv...\n",
            "Dataset loaded: 284807 transactions\n",
            "  Normal: 284315 (99.83%)\n",
            "  Fraud: 492 (0.17%)\n",
            "  Features: 22\n",
            "  Dropped features: 14\n",
            "\n",
            "Data split:\n",
            "  Training: 170589 normal transactions\n",
            "  Validation: 57109 transactions (246 fraud)\n",
            "  Test: 57109 transactions (246 fraud)\n",
            "Data ready.\n"
          ]
        }
      ],
      "source": [
        "handler = FraudDataHandler(\n",
        "    data_path=base_config['data_path'],\n",
        "    random_seed=base_config['random_seed'],\n",
        "    drop_features=base_config['drop_features']\n",
        ")\n",
        "\n",
        "splits = handler.load_and_split()\n",
        "X_train_scaled, X_val_scaled, X_test_scaled = handler.preprocess(\n",
        "    splits['X_train'], splits['X_val'], splits['X_test']\n",
        ")\n",
        "\n",
        "y_train, y_val, y_test = splits['y_train'], splits['y_val'], splits['y_test']\n",
        "\n",
        "print(\"Data ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run Grid Search (cost-based threshold on validation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed 18 configurations\n",
            "Best by validation cost:\n",
            "iterations          400.000000\n",
            "depth                 8.000000\n",
            "learning_rate         0.100000\n",
            "val_cost          22000.000000\n",
            "threshold             0.008046\n",
            "test_cost         25740.000000\n",
            "test_precision        0.841463\n",
            "test_recall           0.841463\n",
            "test_pr_auc           0.861649\n",
            "Name: 15, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "def evaluate_config(iterations, depth, learning_rate):\n",
        "    model = CatBoostClassifier(\n",
        "        iterations=iterations,\n",
        "        depth=depth,\n",
        "        learning_rate=learning_rate,\n",
        "        loss_function='Logloss',\n",
        "        random_seed=base_config['random_seed'],\n",
        "        verbose=False,\n",
        "        allow_writing_files=False,\n",
        "        thread_count=-1\n",
        "    )\n",
        "    X_train_supervised = np.vstack([X_train_scaled, X_val_scaled])\n",
        "    y_train_supervised = np.hstack([y_train, y_val])\n",
        "    model.fit(X_train_supervised, y_train_supervised)\n",
        "\n",
        "    val_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
        "    percentiles = np.arange(1, 100, 0.5)\n",
        "    thresholds = np.percentile(val_proba, percentiles)\n",
        "\n",
        "    C_FP, C_FN = base_config['C_FP'], base_config['C_FN']\n",
        "    def val_cost(th):\n",
        "        y_pred = (val_proba >= th).astype(int)\n",
        "        fp = ((y_val == 0) & (y_pred == 1)).sum()\n",
        "        fn = ((y_val == 1) & (y_pred == 0)).sum()\n",
        "        return fp * C_FP + fn * C_FN\n",
        "\n",
        "    costs = np.array([val_cost(t) for t in thresholds])\n",
        "    best_idx = int(np.argmin(costs))\n",
        "    best_threshold = float(thresholds[best_idx])\n",
        "    best_val_cost = int(costs[best_idx])\n",
        "\n",
        "    # Evaluate on test with best threshold\n",
        "    test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "    y_pred_test = (test_proba >= best_threshold).astype(int)\n",
        "    evaluator = FraudEvaluationMetrics(cost_fp=C_FP, cost_fn=C_FN)\n",
        "    metrics = evaluator.calculate_metrics(y_test, y_pred_test, y_scores=test_proba)\n",
        "\n",
        "    return {\n",
        "        'iterations': iterations,\n",
        "        'depth': depth,\n",
        "        'learning_rate': learning_rate,\n",
        "        'val_cost': best_val_cost,\n",
        "        'threshold': best_threshold,\n",
        "        'test_cost': int(metrics['total_cost']),\n",
        "        'test_precision': float(metrics['precision']),\n",
        "        'test_recall': float(metrics['recall']),\n",
        "        'test_pr_auc': float(metrics['pr_auc']) if metrics['pr_auc'] is not None else None\n",
        "    }\n",
        "\n",
        "results = []\n",
        "for it, d, lr in product(param_grid['iterations'], param_grid['depth'], param_grid['learning_rate']):\n",
        "    res = evaluate_config(it, d, lr)\n",
        "    results.append(res)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(f\"Completed {len(results_df)} configurations\")\n",
        "print(\"Best by validation cost:\")\n",
        "best_row = results_df.loc[results_df['val_cost'].idxmin()]\n",
        "print(best_row)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Analyze and Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: results/tuning/catboost_grid_search_results.csv\n",
            "Saved: results/tuning/catboost_grid_search_detailed.json\n"
          ]
        }
      ],
      "source": [
        "# Save results CSV and JSON summary\n",
        "os.makedirs('../../results/tuning/', exist_ok=True)\n",
        "results_df.to_csv('../../results/tuning/catboost_grid_search_results.csv', index=False)\n",
        "\n",
        "best_row = results_df.loc[results_df['val_cost'].idxmin()].to_dict()\n",
        "with open('../../results/tuning/catboost_grid_search_detailed.json', 'w') as f:\n",
        "    json.dump({\n",
        "        'results': results_df.to_dict(orient='records'),\n",
        "        'best_by_val_cost': best_row\n",
        "    }, f, indent=2)\n",
        "\n",
        "print('Saved: results/tuning/catboost_grid_search_results.csv')\n",
        "print('Saved: results/tuning/catboost_grid_search_detailed.json')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Dev-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
